{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been using gradient boosting models and tuning the parameters almost at random thus far. It's about time I went and understood the method and it's parameters to achieve a better fitting model and be more confident in my final predicitions in the future. Hence I will be using the standard sklearn gradient boost model whilst following along with a tuning tutorial which can be found here:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation and understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the training data\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the test data\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data is:  (42000, 785)\n",
      "The shape of the test data is:  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the training data is: ', df_train.shape)\n",
    "print('The shape of the test data is: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no real need for data preperation here so I will just define the sets clearly now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:,1:785]\n",
    "\n",
    "y_train = df_train.iloc[:,0]\n",
    "\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at one of the entries to better understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have printed a 1\n"
     ]
    }
   ],
   "source": [
    "image = np.array(df_train.iloc[0,1:785], dtype='float')\n",
    "\n",
    "image = image.reshape((28, 28))\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('We have printed a', df_train.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the advice that I will be following:\n",
    "\n",
    "1. Choose a relatively high learning rate. Generally the default value of 0.1 works but somewhere between 0.05 to 0.2 should work for different problems\n",
    "2. Determine the optimum number of trees for this learning rate. This should range around 40-70. Remember to choose a value on which your system can work fairly fast. 3. This is because it will be used for testing various scenarios and determining the tree parameters.\n",
    "4. Tune tree-specific parameters for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "5. Lower the learning rate and increase the estimators proportionally to get more robust models.\n",
    "\n",
    "Tuning tree-specific parameters:\n",
    "\n",
    "1. min_samples_split = 500 : This should be ~0.5-1% of total values. Since this is imbalanced class problem, we’ll take a small value from the range.\n",
    "2. min_samples_leaf = 50 : Can be selected based on intuition. This is just used for preventing overfitting and again a small value because of imbalanced classes.\n",
    "3. max_depth = 8 : Should be chosen (5-8) based on the number of observations and predictors. This has 87K rows and 49 columns so lets take 8 here.\n",
    "4. max_features = ‘sqrt’ : Its a general thumb-rule to start with square root.\n",
    "5. subsample = 0.8 : This is a commonly used used start value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required modules\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_depth=6,\n",
       "                                                  max_features='sqrt',\n",
       "                                                  min_samples_leaf=50,\n",
       "                                                  min_samples_split=400,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={'learning_rate': [0.1],\n",
       "                         'n_estimators': range(20, 100, 10)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct a grid search to find our initial n_estimators and learning rate\n",
    "\n",
    "variable_parameters = {'n_estimators': range(20, 100, 10), 'learning_rate': [0.1]}\n",
    "\n",
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      min_samples_split=400, # ~1% of total values\n",
    "                      min_samples_leaf=50, # as recommended\n",
    "                      max_depth=6, # 5-8 depending on dataset size\n",
    "                      max_features='sqrt', # as recommended\n",
    "                      subsample=0.8 # as recommended\n",
    "                      )\n",
    "\n",
    "# define the model\n",
    "\n",
    "model = GridSearchCV(gbc, variable_parameters, scoring='accuracy', n_jobs=4, cv=5)\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.1, 'n_estimators': 90}, 0.9629523809523809)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90 is a high number of trees to construct each time and so it's worth considering increasing the learning rate slightly to then lower the number of trees, but I have all the time in the world and so 90 will be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tutorial:\n",
    "\n",
    "The order of tuning variables should be decided carefully. You should take the variables with a higher impact on outcome first. For instance, max_depth and min_samples_split have a significant impact and we’re tuning those first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                  min_samples_leaf=50,\n",
       "                                                  n_estimators=90,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={'max_depth': range(5, 16, 2),\n",
       "                         'min_samples_split': range(200, 1001, 200)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct a grid search to find the optimal high impact tree specific parameters\n",
    "\n",
    "variable_parameters = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.1, # as found\n",
    "                      n_estimators=90, # as found\n",
    "                      min_samples_leaf=50, # as recommended\n",
    "                      max_features='sqrt', # as recommended\n",
    "                      subsample=0.8 # as recommended\n",
    "                      )\n",
    "\n",
    "# define the model\n",
    "\n",
    "model = GridSearchCV(gbc, variable_parameters, scoring='accuracy', n_jobs=4, cv=5)\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 15, 'min_samples_split': 200}, 0.9717142857142858)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 is the lowest value that I chose for min_samples_split and so it's worth trying some lower values to try for some more improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                  min_samples_leaf=50,\n",
       "                                                  n_estimators=90,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={'max_depth': range(11, 15),\n",
       "                         'min_samples_split': range(100, 400, 50)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct a grid search to find the optimal high impact tree specific parameters\n",
    "\n",
    "variable_parameters = {'max_depth':range(11,15,1), 'min_samples_split':range(100,400,50)}\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.1, # as found\n",
    "                      n_estimators=90, # as found\n",
    "                      min_samples_leaf=50, # as recommended\n",
    "                      max_features='sqrt', # as recommended\n",
    "                      subsample=0.8 # as recommended\n",
    "                      )\n",
    "\n",
    "# define the model\n",
    "\n",
    "model = GridSearchCV(gbc, variable_parameters, scoring='accuracy', n_jobs=4, cv=5)\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 11, 'min_samples_split': 200}, 0.9723095238095236)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 738 features and so the max_features set at sqrt is using 28. Here is the advice given:\n",
    "\n",
    "\n",
    "    The number of features to consider while searching for a best split. These will be randomly selected.\n",
    "    As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    "    Higher values can lead to over-fitting but depends on case to case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_depth=14,\n",
       "                                                  min_samples_split=100,\n",
       "                                                  n_estimators=90,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={'max_features': range(10, 150, 20),\n",
       "                         'min_samples_leaf': range(20, 100, 20)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct a grid search to find the optimal lesser impact tree specific parameters\n",
    "\n",
    "variable_parameters = {'max_features':range(10,150,20), 'min_samples_leaf':range(20,100,20)}\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.1, # as found\n",
    "                      n_estimators=90, # as found\n",
    "                      max_depth=14, # as found\n",
    "                      min_samples_split=100, # as found\n",
    "                      subsample=0.8 # as recommended\n",
    "                      )\n",
    "\n",
    "# define the model\n",
    "\n",
    "model = GridSearchCV(gbc, variable_parameters, scoring='accuracy', n_jobs=4, cv=5)\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_features': 90, 'min_samples_leaf': 60}, 0.973047619047619)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a nice range for subsample is recommended from 0.6-0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_depth=14, max_features=90,\n",
       "                                                  min_samples_leaf=60,\n",
       "                                                  min_samples_split=100,\n",
       "                                                  n_estimators=90),\n",
       "             n_jobs=4, param_grid={'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct a grid search to find the optimal subsample\n",
    "\n",
    "variable_parameters = {'subsample':[0.5,0.6,0.7,0.8,0.9,1]}\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "\n",
    "# we write the features strangely here since computing the optimal parameters is taking a long time and so it's nice to be able to run each block of code without waiting\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.1, # as found\n",
    "                      n_estimators=90, # as found\n",
    "                      max_depth=14, # as found\n",
    "                      min_samples_split=100, # as found\n",
    "                      max_features=model.best_params_['max_features'], # max_features as found\n",
    "                      min_samples_leaf=model.best_params_['min_samples_leaf'] # min_sample_leaf as found\n",
    "                      )\n",
    "\n",
    "# define the model\n",
    "\n",
    "model = GridSearchCV(gbc, variable_parameters, scoring='accuracy', n_jobs=4, cv=5)\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'subsample': 0.9}, 0.9729047619047619)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tune the learning rate as explained here:\n",
    "\n",
    "Finally, we have all the parameters needed. Now, we need to lower the learning rate and increase the number of estimators proportionally. Note that these trees might not be the most optimum values but a good benchmark.\n",
    "\n",
    "I'll try halving the learning rate while doublin the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.05, # as found\n",
    "                      n_estimators=180, # as found\n",
    "                      max_depth=14, # as found\n",
    "                      min_samples_split=100, # as found\n",
    "                      max_features=90, # max_features as found\n",
    "                      min_samples_leaf=60, # min_sample_leaf as found\n",
    "                      subsample=0.9 # as found\n",
    "                      )\n",
    "\n",
    "# cross validate the classifier to test it's score\n",
    "cv = cross_validate(gbc, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731428571428571"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a marked imporvement and so there's no reason not to try for more. We will again double the trees and halve the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.025, # as found\n",
    "                      n_estimators=360, # as found\n",
    "                      max_depth=14, # as found\n",
    "                      min_samples_split=100, # as found\n",
    "                      max_features=90, # max_features as found\n",
    "                      min_samples_leaf=60, # min_sample_leaf as found\n",
    "                      subsample=0.9 # as found\n",
    "                      )\n",
    "\n",
    "# cross validate the classifier to test it's score\n",
    "cv = cross_validate(gbc, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738809523809524"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see great increases but this took a very long time to do. To alleviate some of the calculations for the next iteration, we'll make use of the warm start parameter of GBC. Again the trees are doubled and the learning rate halved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "                      learning_rate=0.0125, # as found\n",
    "                      n_estimators=720, # as found\n",
    "                      max_depth=14, # as found\n",
    "                      min_samples_split=100, # as found\n",
    "                      max_features=90, # max_features as found\n",
    "                      min_samples_leaf=60, # min_sample_leaf as found\n",
    "                      subsample=0.9, # as found\n",
    "                      warm_start=True # will use the previous runs trees\n",
    "                      )\n",
    "\n",
    "# cross validate the classifier to test it's score\n",
    "cv = cross_validate(gbc, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744999999999999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great result. Perhaps I could go even further but the computstional time is too great. Let's predict the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.0125, max_depth=14, max_features=90,\n",
       "                           min_samples_leaf=60, min_samples_split=100,\n",
       "                           n_estimators=720, subsample=0.9, warm_start=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the classifier\n",
    "\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels of the test set\n",
    "\n",
    "y_test = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the submission format\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# replace the sample labels with our submission labels\n",
    "\n",
    "submission['Label'] = y_test\n",
    "\n",
    "# creat a csv eith the results\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
